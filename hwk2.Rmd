---
output:
  html_document:
    fig_height: 4
    fig_width: 4
---
<p>Elaine Ayo</p>
<p>Math 504</p>
<p>Jan. 25, 2015</p>

```{r setup, echo=FALSE}
knitr::opts_chunk$set(error=TRUE)
```

```{r echo=FALSE}
library(MASS)
library(ggplot2)
library(scatterplot3d)
library(reshape2) 
library(pryr)
library(microbenchmark)
```

<p>2 a)</p>
<p>Graph of function:</p>
```{r, warning=FALSE, message=FALSE, fig.align="center"}
#create a list of functions needed for this problem
p2.fxns <- list(
  #the original function
  f.xy = function(params=list(x=0, y=0)) 2000*(params$x)^2 + (params$y)^2,
  #gradient function
  grad = function(params=data.frame(x=10, y=10)) {
  d.x <- 4000*params$x
  d.y <- 2*params$y
  return(c(d.x,d.y))
  },
  #function to find the norm
  norm = function(x) sqrt(sum(x)^2)
  )

#this will generate a 3-d plot of the function we're looking at
x.s <- seq(-10,10,1)
y.s <- x.s

z <- sapply(1:21, function(i) sapply(1:21, function(j) f.xy(params=data.frame(x=x.s[i],y=y.s[j]))))

base <- persp(x.s, y.s, z, theta = 60, phi = 20, expand = 0.5, col = "lightblue", ltheta = 120, shade = 0.75, border=NA, xlab = "X", ylab = "Y", zlab = "Z") 
base + title("f(x,y) with x,y = [-10,10]")
```

<p>Steepest descent function: </p>
```{r}
descent <- function(initial = c(x=10, y=10), target = 1, step = 1, fxn = p2.fxns) {
  #initialize all the things
  xy <- initial
  grad <- fxn$grad(params=as.list(xy))
  iter <- 0
  path <- NULL
  
  while(fxn$norm(grad) > target ) {
    dir <- -grad / fxn$norm(grad)
    xy <- xy + dir * step
    grad <- fxn$grad(params=as.list(xy))
    path <- rbind(path, xy)
    iter <- iter + 1
  }
  results <- list(final.xy = xy, iterations = iter, fxn.xy = fxn$f.xy(as.list(xy)), path.xy = path)
  return(results)
}
```
```{r}
sizes <- c(.001, .01, .1, 1)

trial1 <- descent(initial = c(x=10, y=10), target = .001, step = .001, fxn = p2.fxns)
trial2 <- descent(initial = c(x=10, y=10), target = .01, step = .01, fxn = p2.fxns)
trial3 <- descent(initial = c(x=10, y=10), target = .1, step = .1, fxn = p2.fxns)
trial4 <- descent(initial = c(x=10, y=10), target = .5, step = 1, fxn = p2.fxns)
```

<p>b)</p>
<p>Bisection function:</p>
```{r}
bisect <- function(xy=data.frame(x=10, y=10), tol=.001, s.a=0, s.b=100, fxn = p2.fxns) {
  s.a <- 0
  s.b <- 100
  s.c <- (s.a + s.b) /2
  grad <- fxn$grad(params=xy)
  direction <- -grad/fxn$norm(grad)
  g.c <- t(fxn$grad(params=(xy+s.c*direction)))%*%direction
  
  while ((s.b-s.a)/2 > tol && abs(g.c) > tol) {
    g.a <- t(fxn$grad(params=(xy+s.a*direction)))%*%direction
    g.c <- t(fxn$grad(params=(xy+s.c*direction)))%*%direction
    
    ifelse(g.a * g.c < 0, s.b <- s.c, s.a <- s.c)
    s.c <- (s.a + s.b) /2  
    g.c <- t(fxn$grad(params=(xy+s.c*direction)))%*%direction
  }
  return(s.c)
}

bisect1 <- bisect()
```

<p>The function finds a minimum at `r bisect1`, which is confirmed as the root by the graph below.</p>

```{r, echo=FALSE, fig.align='center'}
s.a <- seq(-30,30,1)
xy <- data.frame(x=10,y=10)
direction <- -p2.fxns$grad(xy)/p2.fxns$norm(p2.fxns$grad(xy))
g.s <- sapply(1:61, function(x) t(p2.fxns$grad(params=(xy+s.a[x]*direction)))%*%direction)

#h(s)
qplot(x=s.a, y=g.s, geom="line") + ggtitle("g(s) for f(x,y) when x=10 and y=10")
```

<p>Steepest descent function: </p>
```{r}

descent.b <- function(initial = data.frame(x=10, y=10), target = .001, fxn = p2.fxns) {
  #initialize all the things
  xy <- initial
  grad <- fxn$grad(params=as.list(xy))
  iter <- 0
  path <- NULL
  
  while(fxn$norm(grad) > target ) {
    dir <- -grad / fxn$norm(grad)
    step <- bisect(xy)
    xy <- xy + dir * step
    grad <- fxn$grad(params=as.list(xy))
    path <- rbind(path, xy)
    iter <- iter + 1
  }
  results <- list(final.xy = xy, iterations = iter, fxn.xy = fxn$f.xy(as.list(xy)), path.xy = path)
  return(results)
}

trial5 <- descent.b()
```

<p>c)</p>
<table>
<tr>
<td>Trial</td>
<td>Color</td>
<td>Step Size</td>
<td>Tolerance</td>
<td>Iterations</td>
<td>X-Root</td>
<td>Y-Root</td>
<td>f(x,y)</td>
</tr>
<tr>
<td>1</td>
<td>Cyan</td>
<td>`r sizes[1]`</td>
<td>`r sizes[1]`</td>
<td>`r trial1$iterations`</td>
<td>`r trial1$final.xy[1]`</td>
<td>`r trial1$final.xy[2]`</td>
<td>`r trial1$fxn.xy`</td>
</tr>

<tr>
<td>2</td>
<td>Pink</td>
<td>`r sizes[2]`</td>
<td>`r sizes[2]`</td>
<td>`r trial2$iterations`</td>
<td>`r trial2$final.xy[1]`</td>
<td>`r trial2$final.xy[2]`</td>
<td>`r trial2$fxn.xy`</td>
</tr>

<tr>
<td>3</td>
<td>Green</td>
<td>`r sizes[3]`</td>
<td>`r sizes[3]`</td>
<td>`r trial3$iterations`</td>
<td>`r trial3$final.xy[1]`</td>
<td>`r trial3$final.xy[2]`</td>
<td>`r trial3$fxn.xy`</td>
</tr>

<tr>
<td>4</td>
<td>Gray</td>
<td>`r sizes[4]`</td>
<td>`r sizes[4]`</td>
<td>`r trial4$iterations`</td>
<td>`r trial4$final.xy[1]`</td>
<td>`r trial4$final.xy[2]`</td>
<td>`r trial4$fxn.xy`</td>
</tr>

<tr>
<td>4</td>
<td>Red</td>
<td>Bisection Method</td>
<td>.001</td>
<td>`r trial5$iterations`</td>
<td>`r trial5$final.xy[1]`</td>
<td>`r trial5$final.xy[2]`</td>
<td>`r trial5$fxn.xy`</td>
</tr>
</table>

<p>And a graph of the paths:</p>
```{r, warning=FALSE, message=FALSE,  echo=FALSE, fig.align="center"}

x.path1 <- trial1$path.xy[,1]
y.path1 <- trial1$path.xy[,2]

x.path2 <- trial2$path.xy[,1]
y.path2 <- trial2$path.xy[,2]

x.path3 <- trial3$path.xy[,1]
y.path3 <- trial3$path.xy[,2]

x.path4 <- trial4$path.xy[,1]
y.path4 <- trial4$path.xy[,2]

x.path5 <- trial5$path.xy[,1]
y.path5 <- trial5$path.xy[,2]

#this looks better in color
base <- persp(x.s, y.s, z, theta = 60, phi = 30, expand = 0.5, col = "lightblue", ltheta = 120, shade = 0.75, border=NA, xlab = "X", ylab = "Y", zlab = "Z") + title("f(x,y) with various paths to minimum")
lines(trans3d(x=x.path1, y = y.path1, z = f.xy(params=data.frame(x.path1,y.path1)), pmat = base), col = 5, lwd = 1)

base <- persp(x.s, y.s, z, theta = 60, phi = 30, expand = 0.5, col = "lightblue", ltheta = 120, shade = 0.75, border=NA, xlab = "X", ylab = "Y", zlab = "Z") + title("f(x,y) with various paths to minimum")
lines(trans3d(x=x.path2, y = y.path2, z = f.xy(params=data.frame(x.path2,y.path2)), pmat = base), col = 6, lwd = 1)

base <- persp(x.s, y.s, z, theta = 60, phi = 30, expand = 0.5, col = "lightblue", ltheta = 120, shade = 0.75, border=NA, xlab = "X", ylab = "Y", zlab = "Z") + title("f(x,y) with various paths to minimum")
lines(trans3d(x=x.path3+.1, y = y.path3+.1, z = f.xy(params=data.frame(x.path3,y.path3))+.1, pmat = base), col = 3, lwd = 1)

base <- persp(x.s, y.s, z, theta = 60, phi = 30, expand = 0.5, col = "lightblue", ltheta = 120, shade = 0.75, border=NA, xlab = "X", ylab = "Y", zlab = "Z") + title("f(x,y) with various paths to minimum")
lines(trans3d(x=x.path4, y = y.path4, z = f.xy(params=data.frame(x.path4,y.path4)), pmat = base), col = 8, lwd = 4)

base <- persp(x.s, y.s, z, theta = 60, phi = 30, expand = 0.5, col = "lightblue", ltheta = 120, shade = 0.75, border=NA, xlab = "X", ylab = "Y", zlab = "Z") + title("f(x,y) with various paths to minimum")
lines(trans3d(x=x.path5, y = y.path5, z = f.xy(params=data.frame(x.path5,y.path5)), pmat = base), col = 10, lwd = 4)
```

<p>Compared to the fixed step size, the bisection method's path is much shorter and it closely follows the path of step sizes .01/.1. The 2-D plots show that the bisection method jumps to the area around zero much faster than the fixed step sizes.</p>

```{r, fig.align="center", echo=FALSE}
qplot(x.path1, y.path1, geom="line") + xlab("X") + ylab("Y") + ggtitle("Step Size = .001")
qplot(x.path2, y.path2, geom="line") + xlab("X") + ylab("Y") + ggtitle("Step Size = .01")
qplot(x.path3, y.path3, geom="line") + xlab("X") + ylab("Y") + ggtitle("Step Size = .1")
qplot(x.path4, y.path4, geom="line") + xlab("X") + ylab("Y") + ggtitle("Step Size = 1")
qplot(x.path5, y.path5, geom="line") + xlab("X") + ylab("Y") + ggtitle("Bisection Method")
```

<p>3. a)</p>
```{r}
heights <- read.table("children_heights", header=TRUE)

#use melt function to merge data into single function and remove NA's
boys.melt <- melt(heights[,1:3], na.rm= TRUE)
colnames(boys.melt) <- c("Class","Height")

#function to classify single child into height class
class.boys <- function(boy=90) {
  
  #calculate the means
  means <- sapply(1:3, function(x) mean(heights[,x], na.rm=TRUE))
  
  #calculate pooled standard deviation
  sd <- (1/75) * sum(sapply(1:3, function(x) (sum(!is.na(heights[,x]))-1) * sd(heights[,x], na.rm=TRUE) ))
  
  #calculate discriminant and assign to a class
  class <- sapply(1:3, function(x) dnorm(boy, mean=means[x], sd=sd))
  return(which.max(class))
}
```
```{r}
#apply function to all members of data set
classes.boys <- factor(sapply(1:78, function(x) class.boys(boy=boys.melt$Height[x])), labels=c("Boys_2", "Boys_9", "Boys_18"))

#merge predicted classes with actual classes
final.boys <- data.frame(Height=boys.melt$Height, Original=factor(boys.melt$Class), New=classes.boy)

#function to tally percent accurate
compare <- function(data=final.boys) {
  data$total <- sapply(1:78, function(x) ifelse(data$Original[x] == data$New[x], 1, 0))
  classes <- levels(data$Original)
  class.correct <- sapply(1:3, function(x) rbind(classes[x], sum(data$total[which(data$Original == classes[x])])/length(data$total[which(data$Original == classes[x])])  ))
  return(class.correct)
}

#compile final results
results <- compare()

```
<p>All boys are classified correctly.</p> 
`r results`

<p>b)</p>
```{r}
#read in data
heights <- read.table("children_heights", header=TRUE)

#use 'melt' function to turn multi-column data into single column with class assigned, enabling use of sapply over entire data set
kids.melt <- melt(heights, na.rm= TRUE)
colnames(kids.melt) <- c("Class","Height")

#function to assign class to one child
class.kids <- function(kid=90) {
  #find the means
  means <- sapply(1:6, function(x) mean(heights[,x], na.rm=TRUE))
  
  #find the pooled standard deviation
  sd <- (1/168) * sum(sapply(1:6, function(x) (sum(!is.na(heights[,x]))-1) * sd(heights[,x], na.rm=TRUE) ))
  
  #calculate discriminant and choose class
  class <- sapply(1:6, function(x) dnorm(kid, mean=means[x], sd=sd))
  return(as.numeric(which.max(class)))
}
```
```{r}
#call function to assign class on data set
classes.kids <- factor(sapply(1:174, function(x) class.kids(kid=kids.melt$Height[x])),labels=c("Boys_2", "Boys_9", "Boys_18", "Girls_2", "Girls_9", "Girls_18"))

#compile final list of results
final.kids <- data.frame(Height=kids.melt$Height, Original=factor(kids.melt$Class), New=classes.kids)

#function to tally percent accurate, adjusted for entire data set
compare.kids <- function(data=final.kids) {
  total <- sapply(1:174, function(x) ifelse(data$Original[x] == data$New[x], 1, 0))
  classes <- levels(data$Original)
  class.correct <- sapply(1:6, function(x) sum(total[which(data$Original == classes[x])])/length(total[which(data$Original == classes[x])]))
  class.correct <- c(class.correct, sum(total)/length(total))
  names(class.correct) <- c(levels(data$Original), "Total")
  return(class.correct)
}

#tally final results
classes <- c("Boys_2", "Boys_9", "Boys_18", "Girls_2", "Girls_9", "Girls_18")
results.all <- compare.kids(data=final.kids)
```

<p>.6207 children were classified correctly, which was to be expected due to the overlapping age groups. In part a, there were very clean divisions between the height of any child at 2, 9, and 18 years of age. However, with the introduction of a second gender, it became trickier to cleanly classify the data on the basis of both gender and age.</p>

<table>
<tr>
<td>
`r classes[1]`
</td>
<td>
`r results.all[1]`
</td>
</tr>

<tr>
<td>
`r classes[2]`
</td>
<td>
`r results.all[2]`
</td>
</tr>

<tr>
<td>
`r classes[3]`
</td>
<td>
`r results.all[3]`
</td>
</tr>

<tr>
<td>
`r classes[4]`
</td>
<td>
`r results.all[4]`
</td>
</tr>

<tr>
<td>
`r classes[5]`
</td>
<td>
`r results.all[5]`
</td>
</tr>

<tr>
<td>
`r classes[6]`
</td>
<td>
`r results.all[6]`
</td>
</tr>
</table>

<p>c)</p>
```{r}
class.kids.sd <- function(kid=90) {
  #find the means
  means <- sapply(1:6, function(x) mean(heights[,x], na.rm=TRUE))
  
  #find the pooled standard deviation
  sds <- sapply(1:6, function(x) sd(heights[,x], na.rm=TRUE) )
  
  #calculate discriminant and choose class
  class <- sapply(1:6, function(x) dnorm(kid, mean=means[x], sd=sds[x]))
  return(as.numeric(which.max(class)))
}
```
```{r}
#run the function over each height in the data set
classes.kids.sd <- factor(sapply(1:174, function(x) class.kids.sd(kid=kids.melt$Height[x])),labels=c("Boys_2", "Boys_9", "Boys_18", "Girls_2", "Girls_9", "Girls_18"))

#combine the new classes with the old classes
final.kids.sd <- data.frame(Height=kids.melt$Height, Original=factor(kids.melt$Class), New=classes.kids.sd)

#compare for accuracy and compile final table of results
results.all.sd <- compare.kids(data=final.kids.sd)
```

<p>Adding the individual sigmas for the groups slightly improved the classifications, with .6437 being classified correctly.</p>
<table>
<tr>
<td>
`r classes[1]`
</td>
<td>
`r results.all.sd[1]`
</td>
</tr>

<tr>
<td>
`r classes[2]`
</td>
<td>
`r results.all.sd[2]`
</td>
</tr>

<tr>
<td>
`r classes[3]`
</td>
<td>
`r results.all.sd[3]`
</td>
</tr>

<tr>
<td>
`r classes[4]`
</td>
<td>
`r results.all.sd[4]`
</td>
</tr>

<tr>
<td>
`r classes[5]`
</td>
<td>
`r results.all.sd[5]`
</td>
</tr>

<tr>
<td>
`r classes[6]`
</td>
<td>
`r results.all.sd[6]`
</td>
</tr>
</table>

<p>4 a)</p>
```{r}
f.x <- function(x,a) {
  f.x <- x^2 - a
  return(f.x)
}

df.x <- function(x) {
  df.x <- 2*x
  return(df.x)
}

mySqrt.a <- function(a=4, tol=.001) {
  #s.old needs to be larger than the root of a to work
  #since we don't know a, we can't set a constant or an equation, because a can be anywhere
  #from near zero to near infinity, the next best thing is s.old = a if a > 1 and
  #s.old = 1 if a < 1
  #because we know for sure a > sqrt(a) if a > 1, and if a < 1, a = 1 should be larger than the root
  #and a must be positive, otherwise the function goes marching off toward negative infinity because the original f.x doesn't get smaller
  if (a < 0) {
    return("a must be >= 0")
  } else {
    
  s <- ifelse(a > 1, a, 1)
  while(f.x(s, a) > tol) {
    s <- s - f.x(s,a)/df.x(s)
  }
  return(s)
  }
}
```

<p>b) Second order Taylor series</p>
<p>Given:</p> 
<p>$f(x) = x^2 - c$</p>
<p>$f'(x) = 2x$</p>
<p>$f''(x) = 2$</p>
<p>and that the second order Taylor series is: $f(s_0) + \frac{f'(s_0)}{1!}(s-s_0) + \frac{f''(s_0)}{2!}(s-s_0)^2$</p>

<p>where $s_0$ is the previous step for $s$ and $s$ is the step we're calculating.</p>

<p>
Subbing in: $a = 2/2 = 1$, $b = 2s_0$, $c = (s_0^2 - c)$, and $x = s-s_0$, we can use the quadratic equation to find the root.

$$ (s - s_0) = \frac{-2s_0 +/- \sqrt(4s_0^2 - 4(1)(s_0^2 - c))}{2(1)} $$
$$ (s - s_0) = -s_0 +/- \sqrt(s_0^2 - (s_0^2 - c)) $$
$$ s = +/- \sqrt(c) $$
</p>

<p>This makes sense since we're finding the root of a second-order equation, so any further derivatives on the Taylor expansion would be zero, and the second-order Taylor series expresses the complete equation.</p>

```{r}
mySqrt.b <- function(a=4, tol=.001) {
  if (a < 0) {
    return("a must be >= 0")
  } else {
  
  s <- ifelse(a > 1, a, 1)
  while(f.x(s, a) > tol) {
    s <- sqrt(a)
  }
  return(s)
  }
}
```

<p>c) </p>
```{r}
mySqrt.c <- function(a=4) {
  if (a < 0) {
    return("a must be >= 0")
  } else {
  s <- ifelse(a > 1, a, 1)
  root <- uniroot(function(x) x^2 - a, c(0, s), tol = 0.0000001)$root
  return(root)
  }
}
```

<p>d) 
<p>Accuracy</p>
```{r, echo=FALSE}
tests <- c(.05, 10, 5670)
root1 <- sapply(1:3, function(x) mySqrt.a(a=tests[x]))
root2 <- sapply(1:3, function(x) mySqrt.b(a=tests[x]))
root3 <- sapply(1:3, function(x) mySqrt.c(a=tests[x]))
root4 <- sapply(1:3, function(x) sqrt(tests[x]))
```

Comparing accuracy for roots of .05, 10, and 5,670:
<table>
<tr>
<td>MySqrt.a()</td>
<td>`r root1`</td>
</tr>
<tr>
<td>MySqrt.b()</td>
<td>`r root2`</td>
</tr>
<tr>
<td>MySqrt.c()</td>
<td>`r root3`</td>
</tr>
<tr>
<td>sqrt()</td>
<td>`r root4`</td>
</tr>
</table>


<p>Speed:</p>
```{r}
mySqrts <- list(
  mySqrt.a = function(a=4, tol=.001) {
  if (a < 0) {
    return("a must be >= 0")
  } else {
    
  s <- ifelse(a > 1, a, 1)
  while(f.x(s, a) > tol) {
    s <- s - f.x(s,a)/df.x(s)
  }
  return(s)
  }
},
  mySqrt.b = function(a=4, tol=.001) {
  if (a < 0) {
    return("a must be >= 0")
  } else {
  
  s <- ifelse(a > 1, a, 1)
  while(f.x(s, a) > tol) {
    s <- sqrt(a)
  }
  return(s)
  }
},
  mySqrt.c = function(a=4) {
  if (a < 0) {
    return("a must be >= 0")
  } else {
  s <- ifelse(a > 1, a, 1)
  root <- uniroot(function(x) x^2 - a, c(0, s), tol = 0.0000001)$root
  return(root)
  }
  }
)
```
```{r}
speeds <- function() {
  #choose random a
  a <- runif(1,min = 0, max= 100000)
  
  #calculate speeds for all three functions
  speeds <- lapply(1:3, function(x) microbenchmark(mySqrts[[x]](a), times = 100L))
  return(list(a, speeds) )
}
```
<p>As shown below, the second function (which uses R's sqrt() function) is always the fastest, and often four to five times as fast as the function using Newton's method from part a. However, the Newton's method function is consistently twice as fast as the function relying on uniroot, though it does have a lower degree of accuracy than the other two functions.</p>

<p>1: mySqrt.a; 2: mySqrt.b; 3: mySqrt.c</p>
```{r echo=FALSE}
set.seed(1) 
lapply(1:5, function(x) speeds())
```




